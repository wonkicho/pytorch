{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33.3331], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "#linear layer 선언\n",
    "linear_model = nn.Linear(1, 1) #인스턴스화 해서 함수인 것처럼\n",
    "linear_model(torch.tensor([50.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model의 weight, bias 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.6667]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0014], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6653], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(1)\n",
    "linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 최적화\n",
    "\n",
    "- 배치 수행하는 이유 : 연산량을 충분히 크게 만들어서 컴퓨팅 자원 최대한 활용하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9]\n",
    "\n",
    "# 임의로 차원 추가\n",
    "t_c = torch.tensor(t_c).unsqueeze(1)\n",
    "t_u = torch.tensor(t_u).unsqueeze(1)\n",
    "\n",
    "print(t_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(\n",
    "    linear_model.parameters(), lr = 1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.1997]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1640], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        t_p_train = model(t_u_train) #predictions\n",
    "        loss_train = loss_fn(t_p_train, t_c_train) #loss calculation\n",
    "        \n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 1 or epoch % 1000 == 0:\n",
    "            print(f'Epoch {epoch}, Training loss {loss_train.item():.4f}, Validation loss {loss_val.item():.4f}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 290.1488, Validation loss 324.3441\n",
      "Epoch 1000, Training loss nan, Validation loss nan\n",
      "Epoch 2000, Training loss nan, Validation loss nan\n",
      "Epoch 3000, Training loss nan, Validation loss nan\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[nan]], requires_grad=True) Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "t_c_train = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0]).unsqueeze(1)\n",
    "t_c_val = torch.tensor([6.0, 13.0, 21.0]).unsqueeze(1)\n",
    "\n",
    "t_un_train = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9]).unsqueeze(1)\n",
    "t_un_val = torch.tensor([48.4, 60.4, 68.4]).unsqueeze(1)\n",
    "\n",
    "\n",
    "\n",
    "linear_model = nn.Linear(1, 1)\n",
    "optimizer = torch.optim.SGD(linear_model.parameters(), lr = 1e-3)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=3000,\n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val,\n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val\n",
    ")\n",
    "\n",
    "print()\n",
    "print(linear_model.weight, linear_model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(1, 13),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(13, 1)\n",
    ")\n",
    "\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.shape for param in seq_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', Parameter containing:\n",
      "tensor([[ 0.6561],\n",
      "        [-0.6070],\n",
      "        [ 0.0408],\n",
      "        [ 0.0965],\n",
      "        [-0.1624],\n",
      "        [-0.5406],\n",
      "        [-0.0690],\n",
      "        [-0.8924],\n",
      "        [ 0.9006],\n",
      "        [ 0.4805],\n",
      "        [-0.5573],\n",
      "        [ 0.3354],\n",
      "        [ 0.9778]], requires_grad=True))\n",
      "('0.bias', Parameter containing:\n",
      "tensor([ 0.1394, -0.4071, -0.0745,  0.0953, -0.8816, -0.2687, -0.7986,  0.8354,\n",
      "        -0.0917, -0.4309,  0.7145, -0.9079, -0.7487], requires_grad=True))\n",
      "('2.weight', Parameter containing:\n",
      "tensor([[-0.1399, -0.2245,  0.2579,  0.2149, -0.0188,  0.1534,  0.0946, -0.2034,\n",
      "         -0.2162, -0.2158, -0.1338,  0.0037,  0.0343]], requires_grad=True))\n",
      "('2.bias', Parameter containing:\n",
      "tensor([0.0240], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "#출력 결과 확인하기 쉬움\n",
    "\n",
    "for param in seq_model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (8) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11028/1130959798.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mt_u_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_un_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mt_c_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_c_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mt_c_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_c_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11028/4120692153.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mt_p_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_u_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mloss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_p_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_c_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#loss calculation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mt_p_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_u_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch_env1.7\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch_env1.7\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch_env1.7\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2657\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m     \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch_env1.7\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (8) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(1, 8),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "\n",
    "t_c_train = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0]).unsqueeze(1) \n",
    "t_c_val = torch.tensor([6.0, 13.0, 21.0]).unsqueeze(1)\n",
    "\n",
    "t_u_train = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8]).unsqueeze(1) \n",
    "t_u_val = torch.tensor([48.4, 60.4, 68.4]).unsqueeze(1)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(seq_model.parameters(), lr = 1e-3)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=3000,\n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val,\n",
    "    t_c_train = t_c_train,\n",
    "    t_c_val = t_c_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb7accf6f64b3c646c59819a53238b46f0083b41519dcc3c558b975a8260fe68"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('torch_env1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
